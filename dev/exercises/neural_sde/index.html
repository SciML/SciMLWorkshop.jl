<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Training Neural Stochastic Differential Equations with GPU acceleration (I) · SciML Workshop</title><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://docs.sciml.ai/SciMLWorkshop/stable/exercises/neural_sde/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="SciML Workshop logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">SciML Workshop</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">SciMLWorkshop: Workshop Materials for Training in Scientific Computing and Scientific Machine Learning (SciML)</a></li><li><span class="tocitem">Exercises</span><ul><li><a class="tocitem" href="../mtk_chemical_reaction/">ModelingToolkit Simple Chemical Reaction ODE (B)</a></li><li><a class="tocitem" href="../stiffbio_uncertainty/">Investigating Sources of Randomness and Uncertainty in a Stiff Biological System (B)</a></li><li><a class="tocitem" href="../hybriddelay_pharmacokinetics/">Fitting Hybrid Delay Pharmacokinetic Models with Automated Responses (B)</a></li><li><a class="tocitem" href="../dae_double_pendulum/">Differential-Algebraic Equation Modeling of a Double Pendulum (B)</a></li><li><a class="tocitem" href="../acausal_circuit/">RLC Circuit Acausal Model (I)</a></li><li><a class="tocitem" href="../performance_pde/">Performance Optimizing and Parallelizing Semilinear PDE Solvers (I)</a></li><li><a class="tocitem" href="../gsa_henon_heiles/">Global Parameter Sensitivity and Optimality with GPU and Distributed Ensembles (B)</a></li><li class="is-active"><a class="tocitem" href>Training Neural Stochastic Differential Equations with GPU acceleration (I)</a><ul class="internal"><li><a class="tocitem" href="#Part-1:-Constructing-and-Training-a-Basic-Neural-ODE"><span>Part 1: Constructing and Training a Basic Neural ODE</span></a></li><li><a class="tocitem" href="#Part-2:-GPU-accelerating-the-Neural-ODE-Process"><span>Part 2: GPU-accelerating the Neural ODE Process</span></a></li><li><a class="tocitem" href="#Part-3:-Defining-and-Training-a-Mixed-Neural-ODE"><span>Part 3: Defining and Training a Mixed Neural ODE</span></a></li><li><a class="tocitem" href="#Part-4:-Constructing-a-Basic-Neural-SDE"><span>Part 4: Constructing a Basic Neural SDE</span></a></li><li><a class="tocitem" href="#Part-5:-Optimizing-the-training-behavior-with-minibatching-(E)"><span>Part 5: Optimizing the training behavior with minibatching (E)</span></a></li></ul></li><li><a class="tocitem" href="../dc_motor_control/">Controlling a DC Motor (E)</a></li></ul></li><li><span class="tocitem">Selected Solutions</span><ul><li><a class="tocitem" href="../../solutions/mtk_chemical_reaction/">ModelingToolkit Simple Chemical Reaction ODE (B)</a></li><li><a class="tocitem" href="../../solutions/stiffbio_uncertainty/">Investigating Sources of Randomness and Uncertainty in a Stiff Biological System (B)</a></li><li><a class="tocitem" href="../../solutions/hybriddelay_pharmacokinetics/">Fitting Hybrid Delay Pharmacokinetic Models with Automated Responses (B)</a></li><li><a class="tocitem" href="../../solutions/dae_double_pendulum/">Differential-Algebraic Equation Modeling of a Double Pendulum (B)</a></li><li><a class="tocitem" href="../../solutions/acausal_circuit/">RLC Circuit Acausal Model (I)</a></li><li><a class="tocitem" href="../../solutions/performance_pde/">Performance Optimizing and Parallelizing Semilinear PDE Solvers (I)</a></li><li><a class="tocitem" href="../../solutions/gsa_henon_heiles/">Global Parameter Sensitivity and Optimality with GPU and Distributed Ensembles (B)</a></li><li><a class="tocitem" href="../../solutions/neural_sde/">Training Neural Stochastic Differential Equations with GPU acceleration (I)</a></li><li><a class="tocitem" href="../../solutions/dc_motor_control/">Controlling a DC Motor (E)</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Exercises</a></li><li class="is-active"><a href>Training Neural Stochastic Differential Equations with GPU acceleration (I)</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Training Neural Stochastic Differential Equations with GPU acceleration (I)</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/SciML/SciMLWorkshop.jl/blob/main/docs/src/exercises/neural_sde.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Training-Neural-Stochastic-Differential-Equations-with-GPU-acceleration-(I)"><a class="docs-heading-anchor" href="#Training-Neural-Stochastic-Differential-Equations-with-GPU-acceleration-(I)">Training Neural Stochastic Differential Equations with GPU acceleration (I)</a><a id="Training-Neural-Stochastic-Differential-Equations-with-GPU-acceleration-(I)-1"></a><a class="docs-heading-anchor-permalink" href="#Training-Neural-Stochastic-Differential-Equations-with-GPU-acceleration-(I)" title="Permalink"></a></h1><p>In the previous models we had to define a model. Now let&#39;s shift the burden of model-proofing onto data by utilizing neural differential equations. A neural differential equation is a differential equation where the model equations are replaced, either in full or in part, by a neural network. For example, a neural ordinary differential equation is an equation <span>$u^\prime = f(u,p,t)$</span> where <span>$f$</span> is a neural network. We can learn this neural network from data using various methods, the easiest of which is known as the single shooting method, where one chooses neural network parameters, solves the equation, and checks the ODE&#39;s solution against data as a loss.</p><p>In this example we will define and train various forms of neural differential equations. Note that all of the differential equation types are compatible with neural differential equations, so this is only going to scratch the surface of the possibilites!</p><h2 id="Part-1:-Constructing-and-Training-a-Basic-Neural-ODE"><a class="docs-heading-anchor" href="#Part-1:-Constructing-and-Training-a-Basic-Neural-ODE">Part 1: Constructing and Training a Basic Neural ODE</a><a id="Part-1:-Constructing-and-Training-a-Basic-Neural-ODE-1"></a><a class="docs-heading-anchor-permalink" href="#Part-1:-Constructing-and-Training-a-Basic-Neural-ODE" title="Permalink"></a></h2><p>Use the <a href="https://github.com/JuliaDiffEq/DiffEqFlux.jl">DiffEqFlux.jl README</a> to construct a neural ODE to train against the training data:</p><pre><code class="language-julia hljs">u0 = Float32[2.; 0.]
datasize = 30
tspan = (0.0f0,1.5f0)

function trueODEfunc(du,u,p,t)
    true_A = [-0.1 2.0; -2.0 -0.1]
    du .= ((u.^3)&#39;true_A)&#39;
end
t = range(tspan[1],tspan[2],length=datasize)
prob = ODEProblem(trueODEfunc,u0,tspan)
ode_data = Array(solve(prob,Tsit5(),saveat=t))</code></pre><h2 id="Part-2:-GPU-accelerating-the-Neural-ODE-Process"><a class="docs-heading-anchor" href="#Part-2:-GPU-accelerating-the-Neural-ODE-Process">Part 2: GPU-accelerating the Neural ODE Process</a><a id="Part-2:-GPU-accelerating-the-Neural-ODE-Process-1"></a><a class="docs-heading-anchor-permalink" href="#Part-2:-GPU-accelerating-the-Neural-ODE-Process" title="Permalink"></a></h2><p>Use the <code>gpu</code> function from Flux.jl to transform all of the calculations onto the GPU and train the neural ODE using GPU-accelerated <code>Tsit5</code> with adjoints.</p><h2 id="Part-3:-Defining-and-Training-a-Mixed-Neural-ODE"><a class="docs-heading-anchor" href="#Part-3:-Defining-and-Training-a-Mixed-Neural-ODE">Part 3: Defining and Training a Mixed Neural ODE</a><a id="Part-3:-Defining-and-Training-a-Mixed-Neural-ODE-1"></a><a class="docs-heading-anchor-permalink" href="#Part-3:-Defining-and-Training-a-Mixed-Neural-ODE" title="Permalink"></a></h2><p>Gather data from the Lotka-Volterra equation:</p><pre><code class="language-julia hljs">function lotka_volterra(du,u,p,t)
  x, y = u
  α, β, δ, γ = p
  du[1] = dx = α*x - β*x*y
  du[2] = dy = -δ*y + γ*x*y
end
u0 = [1.0,1.0]
tspan = (0.0,10.0)
p = [1.5,1.0,3.0,1.0]
prob = ODEProblem(lotka_volterra,u0,tspan,p)
sol = Array(solve(prob,Tsit5())(0.0:1.0:10.0))</code></pre><p>Now use the <a href="https://github.com/JuliaDiffEq/DiffEqFlux.jl#mixed-neural-des">mixed neural section of the documentation</a> to define the mixed neural ODE where the functional form of <span>$\frac{dx}{dt}$</span> is known, and try to derive a neural formulation for <span>$\frac{dy}{dt}$</span> directly from the data.</p><h2 id="Part-4:-Constructing-a-Basic-Neural-SDE"><a class="docs-heading-anchor" href="#Part-4:-Constructing-a-Basic-Neural-SDE">Part 4: Constructing a Basic Neural SDE</a><a id="Part-4:-Constructing-a-Basic-Neural-SDE-1"></a><a class="docs-heading-anchor-permalink" href="#Part-4:-Constructing-a-Basic-Neural-SDE" title="Permalink"></a></h2><p>Generate data from the Lotka-Volterra equation with multiplicative noise</p><pre><code class="language-julia hljs">function lotka_volterra(du,u,p,t)
  x, y = u
  α, β, δ, γ = p
  du[1] = dx = α*x - β*x*y
  du[2] = dy = -δ*y + γ*x*y
end
function lv_noise(du,u,p,t)
  du[1] = p[5]*u[1]
  du[2] = p[6]*u[2]
end
u0 = [1.0,1.0]
tspan = (0.0,10.0)
p = [1.5,1.0,3.0,1.0,0.1,0.1]
prob = SDEProblem(lotka_volterra,lv_noise,u0,tspan,p)
sol = [Array(solve(prob,SOSRI())(0.0:1.0:10.0)) for i in 1:20] # 20 solution samples</code></pre><p>Train a neural stochastic differential equation <span>$dX = f(X)dt + g(X)dW_t$</span> where both the drift (<span>$f$</span>) and the diffusion (<span>$g$</span>) functions are neural networks. See if constraining <span>$g$</span> can make the problem easier to fit.</p><h2 id="Part-5:-Optimizing-the-training-behavior-with-minibatching-(E)"><a class="docs-heading-anchor" href="#Part-5:-Optimizing-the-training-behavior-with-minibatching-(E)">Part 5: Optimizing the training behavior with minibatching (E)</a><a id="Part-5:-Optimizing-the-training-behavior-with-minibatching-(E)-1"></a><a class="docs-heading-anchor-permalink" href="#Part-5:-Optimizing-the-training-behavior-with-minibatching-(E)" title="Permalink"></a></h2><p>Use minibatching on the data to improve the training procedure. An example <a href="https://github.com/FluxML/model-zoo/pull/88">can be found at this PR</a>.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../gsa_henon_heiles/">« Global Parameter Sensitivity and Optimality with GPU and Distributed Ensembles (B)</a><a class="docs-footer-nextpage" href="../dc_motor_control/">Controlling a DC Motor (E) »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Tuesday 13 December 2022 11:04">Tuesday 13 December 2022</span>. Using Julia version 1.8.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
